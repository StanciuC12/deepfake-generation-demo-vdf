{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC-zteziPhGA",
        "outputId": "4e5cb9e4-8271-4a43-f615-db8a6bddcd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'deepfake-generation-demo-vdf' already exists and is not an empty directory.\n",
            "/content/deepfake-generation-demo-vdf\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/StanciuC12/deepfake-generation-demo-vdf.git\n",
        "%cd deepfake-generation-demo-vdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from LandMarkDetector import LandMarkDetector\n",
        "from DataLoader import DataLoader\n",
        "from train import Encoder, Decoder\n",
        "import os"
      ],
      "metadata": {
        "id": "9-N8UCyeP3iw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "detector = LandMarkDetector()\n",
        "video_adrs = [os.path.join('videos', 'id31_0005.mp4'), os.path.join('videos', 'id19_0006.mp4')]\n",
        "os.mkdir('out')\n",
        "for video_adr in video_adrs:\n",
        "  detector.video2croppedImages(video_path=video_adr, name_prefix=video_adr.split('/')[-1].split('.')[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "218JkrArQLMC",
        "outputId": "9396a271-6d11-420a-b471-0a55e5955102"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILED # 1\n",
            "FAILED # 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "\n",
        "# initialize parameters, data loader, models\n",
        "e = Encoder()\n",
        "e.to('cuda')\n",
        "d1 = Decoder()\n",
        "d1.to('cuda')\n",
        "d2 = Decoder()\n",
        "d2.to('cuda')\n",
        "\n",
        "#parameters###############################################\n",
        "n_epochs = 20\n",
        "lr_e = 1e-4\n",
        "lr_d = 5e-3\n",
        "batch_size=4\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_e = torch.optim.Adam(e.parameters(), lr=lr_e)\n",
        "optimizer_d1 = torch.optim.Adam(d1.parameters(), lr=lr_d)\n",
        "optimizer_d2 = torch.optim.Adam(d2.parameters(), lr=lr_d)\n",
        "##########################################################\n",
        "\n",
        "data_loader = DataLoader(classes=['id19_', 'id31_'], batch_size=batch_size)\n",
        "nr_batches = data_loader.min_batches_each_class\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    # monitor training loss\n",
        "    train_loss = 0.0\n",
        "    data_loader.shuffle_data()\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    for i in range(nr_batches):\n",
        "        print(f'{str(i)}/{str(nr_batches)}')\n",
        "        images_c0 = data_loader.get_data(class_nr=0, batch_nr=i).to('cuda')\n",
        "\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer_e.zero_grad()\n",
        "        optimizer_d1.zero_grad()\n",
        "\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        out1 = d1(e(images_c0))\n",
        "\n",
        "        # calculate the loss\n",
        "        loss1 = criterion(out1, images_c0)\n",
        "        break\n",
        "\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss1.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer_e.step()\n",
        "        optimizer_d1.step()\n",
        "        # update running training loss\n",
        "        train_loss += loss1.item()*images_c0.size(0)\n",
        "\n",
        "\n",
        "        images_c1 = data_loader.get_data(class_nr=1, batch_nr=i).to('cuda')\n",
        "        optimizer_e.zero_grad()\n",
        "        optimizer_d2.zero_grad()\n",
        "        out2 = d2(e(images_c1))\n",
        "        loss2 = criterion(out2, images_c1)\n",
        "        loss2.backward()\n",
        "        optimizer_e.step()\n",
        "        optimizer_d2.step()\n",
        "        train_loss += loss2.item()*images_c1.size(0)\n",
        "\n",
        "    break\n",
        "    # print avg training statistics\n",
        "    train_loss = train_loss/nr_batches\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
        "        epoch,\n",
        "        train_loss\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-9Fr4TARLpn",
        "outputId": "c36af1a3-5a04-4a57-8f89-f0b206050a7f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djDA-dMsVbP1",
        "outputId": "f894a235-299b-4888-ee78-352f88a25ae2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8196, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}